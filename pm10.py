# -*- coding: utf-8 -*-
"""pm10.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WpZFj6jqqNjT9t7U2VZI0rSnSqGd6_SI
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split,cross_val_score
from sklearn.ensemble import VotingRegressor,BaggingRegressor,RandomForestRegressor
from sklearn.tree import DecisionTreeRegressor,plot_tree
from sklearn.svm import SVR
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import r2_score
from sklearn.model_selection import GridSearchCV,RandomizedSearchCV
import matplotlib.pyplot as plt

df = pd.read_excel("pm10.xlsx",engine="openpyxl")

df.sample(5)

df = df.iloc[:,1:]

df.sample()

df.shape

df.info()

df.describe()

df.isnull().sum()

X_train,X_test,y_train,y_test = train_test_split(df.drop(['PM10'],axis=1),df['PM10'],test_size=0.15,random_state=42)

"""#decisionregressor #svr #kneigbhors"""

cls_d = DecisionTreeRegressor()
cls_k = KNeighborsRegressor()
cls_s = SVR()

cls_d.fit(X_train,y_train)
cls_k.fit(X_train,y_train)
cls_s.fit(X_train,y_train)

ypred_d = cls_d.predict(X_test)
ypred_k = cls_k.predict(X_test)
ypred_s = cls_s.predict(X_test)

print(r2_score(y_test,ypred_d))
print(r2_score(y_test,ypred_k))
print(r2_score(y_test,ypred_s))

"""#votingregressor"""

cls_v = VotingRegressor(estimators=[('clsd',cls_d),('clsk',cls_k)])

cls_v.fit(X_train,y_train)

ypred_v = cls_v.predict(X_test)

print(r2_score(y_test,ypred_v))

print(np.mean(cross_val_score(cls_v,X_train,y_train,cv=10)))

"""#Baggingregressor"""

cls_b = BaggingRegressor(estimator=KNeighborsRegressor(),n_estimators=100,bootstrap=True)

cls_b.fit(X_train,y_train)

ypred_b = cls_b.predict(X_test)

print(r2_score(y_test,ypred_b))

print(np.mean(cross_val_score(cls_b,X_train,y_train,cv=10)))

"""#randomforestregressor"""

cls_rf = RandomForestRegressor()
cls_rf.fit(X_train,y_train)

ypred_rf = cls_rf.predict(X_test)

print(r2_score(y_test,ypred_rf))

print(np.mean(cross_val_score(cls_rf,X_train,y_train,cv=10)))

# RandomForestRegressor - 0.7739129822670746
# votingensemble - 0.6978028292868683
# baggingensemble - 0.6352634150937035
# decisiontree - 0.5788291153243623
# kneighbours - 0.6216071148059296
# svr - 0.2698124796439192


